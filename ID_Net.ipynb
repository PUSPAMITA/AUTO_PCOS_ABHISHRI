{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec389a67-06ab-440d-8281-91c4674848f1",
   "metadata": {},
   "source": [
    "## Splitting dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc2619-3d80-4841-9d52-670cc95e29bd",
   "metadata": {},
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "### Splitting data\n",
    "\n",
    "def load_data(train_folder, test_folder):\n",
    "    def load_images_from_folder(folder):\n",
    "        images = []\n",
    "        labels = []\n",
    "        for label in os.listdir(folder):\n",
    "            label_path = os.path.join(folder, label)\n",
    "            if os.path.isdir(label_path):\n",
    "                i=1\n",
    "                for filename in os.listdir(label_path):\n",
    "                    img_path = os.path.join(label_path, filename)\n",
    "                    img = Image.open(img_path)\n",
    "                    img = img.resize((128, 128))\n",
    "                    img = img.convert(\"L\")\n",
    "                    img_array = np.array(img)\n",
    "                    images.append(img_array)\n",
    "                    labels.append(label)\n",
    "                    #print(img.size)\n",
    "                    #print(\"Label path: \", label_path, \"-\",i)\n",
    "                    i=i+1\n",
    "        return np.array(images), np.array(labels)\n",
    "\n",
    "    X_train, y_train = load_images_from_folder(train_folder)\n",
    "    X_test, y_test = load_images_from_folder(test_folder)\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "# Specify the paths to your train and test folders\n",
    "train_folder = r'D:\\PCOS_Challenge\\train'\n",
    "val_folder = r'D:\\PCOS_Challenge\\validate'\n",
    "\n",
    "# Load the custom MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = load_data(train_folder, val_folder)\n",
    "\n",
    "\n",
    "# Print the shape of the training and testing datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f50cdcda-6106-4137-b8fe-02ceef4ff35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2240, 128, 128)\n",
      "y_train shape: (2240,)\n",
      "X_val shape: (864, 128, 128)\n",
      "y_val shape: (864,)\n",
      "X_test shape: (96, 128, 128)\n",
      "y_test shape: (96,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(image_folder, validation_size=0.3, test_size=0.1):\n",
    "    def load_images_from_folder(folder):\n",
    "        images = []\n",
    "        labels = []\n",
    "        for label in os.listdir(folder):\n",
    "            label_path = os.path.join(folder, label)\n",
    "            if os.path.isdir(label_path):\n",
    "                i = 1\n",
    "                for filename in os.listdir(label_path):\n",
    "                    img_path = os.path.join(label_path, filename)\n",
    "                    img = Image.open(img_path)\n",
    "                    img = img.resize((128, 128))\n",
    "                    img = img.convert(\"L\")\n",
    "                    img_array = np.array(img)\n",
    "                    images.append(img_array)\n",
    "                    labels.append(label)\n",
    "                    i = i + 1\n",
    "        return np.array(images), np.array(labels)\n",
    "\n",
    "    # Load data for training and validation\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(*load_images_from_folder(image_folder),\n",
    "                                                        test_size=validation_size,\n",
    "                                                        random_state=42, shuffle = True)\n",
    "    \n",
    "    # Further split the temporary data into validation and test sets\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=test_size,\n",
    "                                                    random_state=42, shuffle = True)\n",
    "\n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "# Specify the paths to your train, validation, and test folders\n",
    "train_folder = r'D:\\PCOS_Challenge\\train'\n",
    "val_folder = r'D:\\PCOS_Challenge\\validate'\n",
    "test_folder = r'D:\\PCOS_Challenge\\test'\n",
    "\n",
    "image_folder = r'D:\\PCOS_Challenge\\Newer_Version\\original_data'\n",
    "\n",
    "# Load the custom dataset with train, validation, and test sets\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = load_data(image_folder)\n",
    "\n",
    "# Print the shape of the training, validation, and testing datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "X_test /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8a6f2ea4-4539-4aba-84ff-607f259025ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unhealthy', 'unhealthy', 'unhealthy', ..., 'unhealthy', 'healthy',\n",
       "       'unhealthy'], dtype='<U9')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "39734c5f-83ac-49e7-b4b0-9be07e7a41bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'healthy', 'healthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'healthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'healthy', 'healthy', 'healthy', 'healthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'healthy', 'healthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'healthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'healthy', 'healthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'healthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'healthy', 'unhealthy', 'healthy',\n",
       "       'healthy', 'healthy', 'healthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'healthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'healthy', 'healthy',\n",
       "       'healthy', 'unhealthy', 'healthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'healthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'healthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'healthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'healthy', 'healthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'healthy', 'healthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'healthy', 'unhealthy', 'healthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'healthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'healthy', 'healthy',\n",
       "       'unhealthy', 'healthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'healthy', 'unhealthy',\n",
       "       'healthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'healthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'healthy', 'unhealthy',\n",
       "       'healthy', 'healthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'healthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'healthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'healthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'healthy', 'healthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'healthy', 'healthy', 'healthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'healthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'healthy', 'healthy',\n",
       "       'healthy', 'healthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'healthy', 'unhealthy', 'healthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'healthy', 'healthy', 'unhealthy',\n",
       "       'healthy', 'healthy', 'healthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'healthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'healthy', 'unhealthy', 'healthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'healthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy'], dtype='<U9')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ead0a44f-55b1-4f89-8092-27ea636e6493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'healthy', 'healthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'healthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'healthy', 'healthy',\n",
       "       'healthy', 'unhealthy', 'healthy', 'healthy', 'healthy',\n",
       "       'unhealthy', 'unhealthy', 'healthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy', 'unhealthy',\n",
       "       'unhealthy', 'unhealthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'healthy', 'healthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'unhealthy', 'healthy', 'unhealthy', 'healthy', 'unhealthy',\n",
       "       'healthy'], dtype='<U9')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b9159692-ca86-424d-a1b8-c023f7d0271a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['healthy', 'unhealthy']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit([\"healthy\", \"unhealthy\"])\n",
    "list(label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9bfb6ce1-d046-4020-9da8-337510bf699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7f953496-f88a-4326-8614-e94739ba3a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8168ccfc-75f0-4aed-95be-250d19f05116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train_encoded)\n",
    "y_val_one_hot = to_categorical(y_val_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5edff4e7-94e2-46e8-bf58-0b60ee1a6289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "764d56b3-5208-4821-888b-cc57a29b42f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a227e3-f4b4-420b-b9b0-32c796c89277",
   "metadata": {},
   "source": [
    "## ID_Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cfa40ec0-dadf-4660-b738-e8df17d19411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization, Add, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e414393d-697d-4b8f-931a-ab7b7c5dfdba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(X_train.shape[0]/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4535e083-2fff-484a-bffd-3ff692138a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NUM = 2\n",
    "BATCH_SIZE = 2\n",
    "EPOCH_STEPS = int(X_train.shape[0]/BATCH_SIZE)\n",
    "IMAGE_SHAPE = (128, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9d03d79c-b776-4ed8-972e-e93d09013558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "def resnet(x, filters):\n",
    "\n",
    "    X_shortcut = x\n",
    "     # 1x1\n",
    "    path1 = Conv2D(filters=filters[0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(x)\n",
    "    path1 = BatchNormalization()(path1)\n",
    "    path1 = Activation('relu')(path1)\n",
    "    \n",
    "    # 1x1->3x3\n",
    "    path2 = Conv2D(filters=filters[1][0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(path1)\n",
    "    path2 = Conv2D(filters=filters[1][1], kernel_size=(3,3), strides=1, padding='same', activation='relu')(path2)\n",
    "    path2 = BatchNormalization()(path2)\n",
    "    path2 = Activation('relu')(path2)\n",
    "    \n",
    "    # 1x1->5x5\n",
    "    path3 = Conv2D(filters=filters[2][0], kernel_size=(1,1), strides=1, padding='same', activation='relu')(path2)\n",
    "    path3 = Conv2D(filters=filters[2][1], kernel_size=(5,5), strides=1, padding='same', activation='relu')(path3)\n",
    "    path3 = BatchNormalization()(path3)\n",
    "    path3 = Activation('relu')(path3)\n",
    "    \n",
    "    # 3x3->1x1\n",
    "    path4 = MaxPooling2D(pool_size=(3,3), strides=1, padding='same')(path3)\n",
    "    path4 = Conv2D(filters=filters[3], kernel_size=(1,1), strides=1, padding='same', activation='relu')(path4)\n",
    "\n",
    "    X_shortcut = Conv2D(filters=filters[3], kernel_size=(1,1), strides=1, padding='same')(X_shortcut)\n",
    "    # Add shortcut value to main path\n",
    "    X = Add()([X_shortcut, path4])\n",
    "    X = Activation('relu')(path4)\n",
    "    \n",
    "    return X\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def auxiliary(x, name=None):\n",
    "    layer = AveragePooling2D(pool_size=(5,5), strides=3, padding='valid')(x)\n",
    "    layer = Conv2D(filters=128, kernel_size=(1,1), strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(units=256, activation='relu')(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "    layer = Dense(units=CLASS_NUM, activation='softmax', name=name)(layer)\n",
    "    \n",
    "    \n",
    "    return layer\n",
    "\n",
    "\n",
    "def googlenet():\n",
    "    layer_in = Input(shape=IMAGE_SHAPE)\n",
    "    #layer_in = resnet_50.input\n",
    "    \n",
    "    # stage-1\n",
    "    layer = Conv2D(filters=64, kernel_size=(7,7), strides=2, padding='same', activation='relu')(layer_in)\n",
    "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "\n",
    "    # stage-2\n",
    "    layer = Conv2D(filters=64, kernel_size=(1,1), strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = Conv2D(filters=192, kernel_size=(3,3), strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
    "\n",
    "    # stage-3\n",
    "    layer = Conv2D(filters=96, kernel_size=(3,3), strides=1, padding='same', activation='relu')(layer)\n",
    "    #layer = inception(layer, [ 64,  (96,128), (16,32), 32]) #3a\n",
    "    #layer = inception(layer, [128, (128,192), (32,96), 64]) #3b\n",
    "    layer = resnet(layer, [ 64,  (96,128), (16,32), 32])\n",
    "    layer = resnet(layer, filters = [128, (128,192), (32,96), 64])\n",
    "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
    "    \n",
    "    # stage-4\n",
    "    layer = Conv2D(filters=96, kernel_size=(3,3), strides=1, padding='same', activation='relu')(layer)\n",
    "    #layer = inception(layer, [192,  (96,208),  (16,48),  64]) #4a\n",
    "    layer = resnet(layer, [192,  (96,208),  (16,48),  64]) #4a\n",
    "    aux1  = auxiliary(layer, name='aux1')\n",
    "    #layer = inception(layer, [160, (112,224),  (24,64),  64]) #4b\n",
    "    #layer = inception(layer, [128, (128,256),  (24,64),  64]) #4c\n",
    "    #layer = inception(layer, [112, (144,288),  (32,64),  64]) #4d\n",
    "    layer = Conv2D(filters=112, kernel_size=(3,3), strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = resnet(layer, [160, (112,224),  (24,64),  64]) #4b\n",
    "    layer = resnet(layer, [128, (128,256),  (24,64),  64]) #4c\n",
    "    layer = resnet(layer, [112, (144,288),  (32,64),  64]) #4d\n",
    "    aux2  = auxiliary(layer, name='aux2')\n",
    "    #layer = inception(layer, [256, (160,320), (32,128), 128]) #4e\n",
    "    #layer = Conv2D(filters=320, kernel_size=(3,3), strides=1, padding='same', activation='relu')(layer)\n",
    "    layer = resnet(layer, [256, (160,320), (32,128), 128])\n",
    "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
    "    \n",
    "    layer = AveragePooling2D(pool_size=(7,7), strides=(1, 1), padding='same')(layer)\n",
    "\n",
    "    #layer = resnet_50.output\n",
    "    \n",
    "    # stage-6\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dropout(0.4)(layer)\n",
    "    layer = Dense(units=256, activation='linear')(layer)\n",
    "    main = Dense(units=CLASS_NUM, activation='softmax', name='main')(layer)\n",
    "    \n",
    "    model = Model(inputs=layer_in, outputs=[main, aux1, aux2])\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17df8d8b-1ec1-42a1-92b5-7b412d3e8505",
   "metadata": {},
   "source": [
    "## Model Summery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "531446e9-84ab-46a8-8472-f6c566739b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 128, 128, 1)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_228 (Conv2D)         (None, 64, 64, 64)           3200      ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_44 (MaxPooli  (None, 32, 32, 64)           0         ['conv2d_228[0][0]']          \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " batch_normalization_92 (Ba  (None, 32, 32, 64)           256       ['max_pooling2d_44[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_229 (Conv2D)         (None, 32, 32, 64)           4160      ['batch_normalization_92[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_230 (Conv2D)         (None, 32, 32, 192)          110784    ['conv2d_229[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_93 (Ba  (None, 32, 32, 192)          768       ['conv2d_230[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_45 (MaxPooli  (None, 16, 16, 192)          0         ['batch_normalization_93[0][0]\n",
      " ng2D)                                                              ']                            \n",
      "                                                                                                  \n",
      " conv2d_231 (Conv2D)         (None, 16, 16, 96)           165984    ['max_pooling2d_45[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_232 (Conv2D)         (None, 16, 16, 64)           6208      ['conv2d_231[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_94 (Ba  (None, 16, 16, 64)           256       ['conv2d_232[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_112 (Activation  (None, 16, 16, 64)           0         ['batch_normalization_94[0][0]\n",
      " )                                                                  ']                            \n",
      "                                                                                                  \n",
      " conv2d_233 (Conv2D)         (None, 16, 16, 96)           6240      ['activation_112[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_234 (Conv2D)         (None, 16, 16, 128)          110720    ['conv2d_233[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_95 (Ba  (None, 16, 16, 128)          512       ['conv2d_234[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_113 (Activation  (None, 16, 16, 128)          0         ['batch_normalization_95[0][0]\n",
      " )                                                                  ']                            \n",
      "                                                                                                  \n",
      " conv2d_235 (Conv2D)         (None, 16, 16, 16)           2064      ['activation_113[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_236 (Conv2D)         (None, 16, 16, 32)           12832     ['conv2d_235[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_96 (Ba  (None, 16, 16, 32)           128       ['conv2d_236[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_114 (Activation  (None, 16, 16, 32)           0         ['batch_normalization_96[0][0]\n",
      " )                                                                  ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_46 (MaxPooli  (None, 16, 16, 32)           0         ['activation_114[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_237 (Conv2D)         (None, 16, 16, 32)           1056      ['max_pooling2d_46[0][0]']    \n",
      "                                                                                                  \n",
      " activation_115 (Activation  (None, 16, 16, 32)           0         ['conv2d_237[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_239 (Conv2D)         (None, 16, 16, 128)          4224      ['activation_115[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_97 (Ba  (None, 16, 16, 128)          512       ['conv2d_239[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_116 (Activation  (None, 16, 16, 128)          0         ['batch_normalization_97[0][0]\n",
      " )                                                                  ']                            \n",
      "                                                                                                  \n",
      " conv2d_240 (Conv2D)         (None, 16, 16, 128)          16512     ['activation_116[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_241 (Conv2D)         (None, 16, 16, 192)          221376    ['conv2d_240[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_98 (Ba  (None, 16, 16, 192)          768       ['conv2d_241[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_117 (Activation  (None, 16, 16, 192)          0         ['batch_normalization_98[0][0]\n",
      " )                                                                  ']                            \n",
      "                                                                                                  \n",
      " conv2d_242 (Conv2D)         (None, 16, 16, 32)           6176      ['activation_117[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_243 (Conv2D)         (None, 16, 16, 96)           76896     ['conv2d_242[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_99 (Ba  (None, 16, 16, 96)           384       ['conv2d_243[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " activation_118 (Activation  (None, 16, 16, 96)           0         ['batch_normalization_99[0][0]\n",
      " )                                                                  ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_47 (MaxPooli  (None, 16, 16, 96)           0         ['activation_118[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_244 (Conv2D)         (None, 16, 16, 64)           6208      ['max_pooling2d_47[0][0]']    \n",
      "                                                                                                  \n",
      " activation_119 (Activation  (None, 16, 16, 64)           0         ['conv2d_244[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_48 (MaxPooli  (None, 8, 8, 64)             0         ['activation_119[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_246 (Conv2D)         (None, 8, 8, 96)             55392     ['max_pooling2d_48[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_247 (Conv2D)         (None, 8, 8, 192)            18624     ['conv2d_246[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_100 (B  (None, 8, 8, 192)            768       ['conv2d_247[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_120 (Activation  (None, 8, 8, 192)            0         ['batch_normalization_100[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_248 (Conv2D)         (None, 8, 8, 96)             18528     ['activation_120[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_249 (Conv2D)         (None, 8, 8, 208)            179920    ['conv2d_248[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_101 (B  (None, 8, 8, 208)            832       ['conv2d_249[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_121 (Activation  (None, 8, 8, 208)            0         ['batch_normalization_101[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_250 (Conv2D)         (None, 8, 8, 16)             3344      ['activation_121[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_251 (Conv2D)         (None, 8, 8, 48)             19248     ['conv2d_250[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_102 (B  (None, 8, 8, 48)             192       ['conv2d_251[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_122 (Activation  (None, 8, 8, 48)             0         ['batch_normalization_102[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_49 (MaxPooli  (None, 8, 8, 48)             0         ['activation_122[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_252 (Conv2D)         (None, 8, 8, 64)             3136      ['max_pooling2d_49[0][0]']    \n",
      "                                                                                                  \n",
      " activation_123 (Activation  (None, 8, 8, 64)             0         ['conv2d_252[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_255 (Conv2D)         (None, 8, 8, 112)            64624     ['activation_123[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_256 (Conv2D)         (None, 8, 8, 160)            18080     ['conv2d_255[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_103 (B  (None, 8, 8, 160)            640       ['conv2d_256[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_124 (Activation  (None, 8, 8, 160)            0         ['batch_normalization_103[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_257 (Conv2D)         (None, 8, 8, 112)            18032     ['activation_124[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_258 (Conv2D)         (None, 8, 8, 224)            226016    ['conv2d_257[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_104 (B  (None, 8, 8, 224)            896       ['conv2d_258[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_125 (Activation  (None, 8, 8, 224)            0         ['batch_normalization_104[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_259 (Conv2D)         (None, 8, 8, 24)             5400      ['activation_125[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_260 (Conv2D)         (None, 8, 8, 64)             38464     ['conv2d_259[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_105 (B  (None, 8, 8, 64)             256       ['conv2d_260[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_126 (Activation  (None, 8, 8, 64)             0         ['batch_normalization_105[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_50 (MaxPooli  (None, 8, 8, 64)             0         ['activation_126[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_261 (Conv2D)         (None, 8, 8, 64)             4160      ['max_pooling2d_50[0][0]']    \n",
      "                                                                                                  \n",
      " activation_127 (Activation  (None, 8, 8, 64)             0         ['conv2d_261[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_263 (Conv2D)         (None, 8, 8, 128)            8320      ['activation_127[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_106 (B  (None, 8, 8, 128)            512       ['conv2d_263[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_128 (Activation  (None, 8, 8, 128)            0         ['batch_normalization_106[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_264 (Conv2D)         (None, 8, 8, 128)            16512     ['activation_128[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_265 (Conv2D)         (None, 8, 8, 256)            295168    ['conv2d_264[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_107 (B  (None, 8, 8, 256)            1024      ['conv2d_265[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_129 (Activation  (None, 8, 8, 256)            0         ['batch_normalization_107[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_266 (Conv2D)         (None, 8, 8, 24)             6168      ['activation_129[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_267 (Conv2D)         (None, 8, 8, 64)             38464     ['conv2d_266[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_108 (B  (None, 8, 8, 64)             256       ['conv2d_267[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_130 (Activation  (None, 8, 8, 64)             0         ['batch_normalization_108[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_51 (MaxPooli  (None, 8, 8, 64)             0         ['activation_130[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_268 (Conv2D)         (None, 8, 8, 64)             4160      ['max_pooling2d_51[0][0]']    \n",
      "                                                                                                  \n",
      " activation_131 (Activation  (None, 8, 8, 64)             0         ['conv2d_268[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_270 (Conv2D)         (None, 8, 8, 112)            7280      ['activation_131[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_109 (B  (None, 8, 8, 112)            448       ['conv2d_270[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_132 (Activation  (None, 8, 8, 112)            0         ['batch_normalization_109[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_271 (Conv2D)         (None, 8, 8, 144)            16272     ['activation_132[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_272 (Conv2D)         (None, 8, 8, 288)            373536    ['conv2d_271[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_110 (B  (None, 8, 8, 288)            1152      ['conv2d_272[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_133 (Activation  (None, 8, 8, 288)            0         ['batch_normalization_110[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_273 (Conv2D)         (None, 8, 8, 32)             9248      ['activation_133[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_274 (Conv2D)         (None, 8, 8, 64)             51264     ['conv2d_273[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_111 (B  (None, 8, 8, 64)             256       ['conv2d_274[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_134 (Activation  (None, 8, 8, 64)             0         ['batch_normalization_111[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_52 (MaxPooli  (None, 8, 8, 64)             0         ['activation_134[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_275 (Conv2D)         (None, 8, 8, 64)             4160      ['max_pooling2d_52[0][0]']    \n",
      "                                                                                                  \n",
      " activation_135 (Activation  (None, 8, 8, 64)             0         ['conv2d_275[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_278 (Conv2D)         (None, 8, 8, 256)            16640     ['activation_135[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_112 (B  (None, 8, 8, 256)            1024      ['conv2d_278[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_136 (Activation  (None, 8, 8, 256)            0         ['batch_normalization_112[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_279 (Conv2D)         (None, 8, 8, 160)            41120     ['activation_136[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_280 (Conv2D)         (None, 8, 8, 320)            461120    ['conv2d_279[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_113 (B  (None, 8, 8, 320)            1280      ['conv2d_280[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_137 (Activation  (None, 8, 8, 320)            0         ['batch_normalization_113[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " conv2d_281 (Conv2D)         (None, 8, 8, 32)             10272     ['activation_137[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_282 (Conv2D)         (None, 8, 8, 128)            102528    ['conv2d_281[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_114 (B  (None, 8, 8, 128)            512       ['conv2d_282[0][0]']          \n",
      " atchNormalization)                                                                               \n",
      "                                                                                                  \n",
      " activation_138 (Activation  (None, 8, 8, 128)            0         ['batch_normalization_114[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " max_pooling2d_53 (MaxPooli  (None, 8, 8, 128)            0         ['activation_138[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_283 (Conv2D)         (None, 8, 8, 128)            16512     ['max_pooling2d_53[0][0]']    \n",
      "                                                                                                  \n",
      " activation_139 (Activation  (None, 8, 8, 128)            0         ['conv2d_283[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_54 (MaxPooli  (None, 4, 4, 128)            0         ['activation_139[0][0]']      \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " average_pooling2d_12 (Aver  (None, 2, 2, 64)             0         ['activation_123[0][0]']      \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " average_pooling2d_13 (Aver  (None, 2, 2, 64)             0         ['activation_135[0][0]']      \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " average_pooling2d_14 (Aver  (None, 4, 4, 128)            0         ['max_pooling2d_54[0][0]']    \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_254 (Conv2D)         (None, 2, 2, 128)            8320      ['average_pooling2d_12[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_277 (Conv2D)         (None, 2, 2, 128)            8320      ['average_pooling2d_13[0][0]']\n",
      "                                                                                                  \n",
      " flatten_14 (Flatten)        (None, 2048)                 0         ['average_pooling2d_14[0][0]']\n",
      "                                                                                                  \n",
      " flatten_12 (Flatten)        (None, 512)                  0         ['conv2d_254[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_13 (Flatten)        (None, 512)                  0         ['conv2d_277[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)        (None, 2048)                 0         ['flatten_14[0][0]']          \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 256)                  131328    ['flatten_12[0][0]']          \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 256)                  131328    ['flatten_13[0][0]']          \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 256)                  524544    ['dropout_14[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)        (None, 256)                  0         ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)        (None, 256)                  0         ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      " main (Dense)                (None, 2)                    514       ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      " aux1 (Dense)                (None, 2)                    514       ['dropout_12[0][0]']          \n",
      "                                                                                                  \n",
      " aux2 (Dense)                (None, 2)                    514       ['dropout_13[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3725366 (14.21 MB)\n",
      "Trainable params: 3718550 (14.19 MB)\n",
      "Non-trainable params: 6816 (26.62 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model = googlenet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf1181-0010-4aeb-8434-0e1d86e3f820",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9eb759-c28f-4e8a-895d-59b4a4a08dc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usnig optimizer: Adam, Epoch: 50\n",
      "Epoch 1/50\n",
      "1120/1120 [==============================] - 66s 51ms/step - loss: 1.2843 - main_loss: 0.9085 - aux1_loss: 0.6190 - aux2_loss: 0.6338 - main_accuracy: 0.7188 - aux1_accuracy: 0.7183 - aux2_accuracy: 0.7152 - val_loss: 3.1691 - val_main_loss: 0.6158 - val_aux1_loss: 1.0089 - val_aux2_loss: 7.5023 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 2/50\n",
      "1120/1120 [==============================] - 55s 49ms/step - loss: 0.9486 - main_loss: 0.5915 - aux1_loss: 0.5954 - aux2_loss: 0.5950 - main_accuracy: 0.7241 - aux1_accuracy: 0.7263 - aux2_accuracy: 0.7272 - val_loss: 1.5309 - val_main_loss: 0.6193 - val_aux1_loss: 0.7117 - val_aux2_loss: 2.3271 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 3/50\n",
      "1120/1120 [==============================] - 54s 49ms/step - loss: 0.9490 - main_loss: 0.5935 - aux1_loss: 0.5894 - aux2_loss: 0.5956 - main_accuracy: 0.7263 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 1.1198 - val_main_loss: 0.6236 - val_aux1_loss: 0.6544 - val_aux2_loss: 0.9993 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 4/50\n",
      "1120/1120 [==============================] - 54s 48ms/step - loss: 0.9487 - main_loss: 0.5956 - aux1_loss: 0.5861 - aux2_loss: 0.5908 - main_accuracy: 0.7250 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 1.0024 - val_main_loss: 0.6144 - val_aux1_loss: 0.6241 - val_aux2_loss: 0.6693 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6968 - val_aux2_accuracy: 0.6956\n",
      "Epoch 5/50\n",
      "1120/1120 [==============================] - 55s 49ms/step - loss: 0.9380 - main_loss: 0.5897 - aux1_loss: 0.5727 - aux2_loss: 0.5881 - main_accuracy: 0.7272 - aux1_accuracy: 0.7268 - aux2_accuracy: 0.7272 - val_loss: 0.9852 - val_main_loss: 0.6148 - val_aux1_loss: 0.6094 - val_aux2_loss: 0.6255 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 6/50\n",
      "1120/1120 [==============================] - 53s 47ms/step - loss: 0.9360 - main_loss: 0.5909 - aux1_loss: 0.5605 - aux2_loss: 0.5899 - main_accuracy: 0.7272 - aux1_accuracy: 0.7317 - aux2_accuracy: 0.7272 - val_loss: 0.9810 - val_main_loss: 0.6148 - val_aux1_loss: 0.6012 - val_aux2_loss: 0.6193 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.7049 - val_aux2_accuracy: 0.6956\n",
      "Epoch 7/50\n",
      "1120/1120 [==============================] - 51s 46ms/step - loss: 0.9355 - main_loss: 0.5949 - aux1_loss: 0.5455 - aux2_loss: 0.5897 - main_accuracy: 0.7272 - aux1_accuracy: 0.7393 - aux2_accuracy: 0.7272 - val_loss: 0.9988 - val_main_loss: 0.6154 - val_aux1_loss: 0.5823 - val_aux2_loss: 0.6955 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6968 - val_aux2_accuracy: 0.6956\n",
      "Epoch 8/50\n",
      "1120/1120 [==============================] - 49s 44ms/step - loss: 0.9278 - main_loss: 0.5880 - aux1_loss: 0.5426 - aux2_loss: 0.5901 - main_accuracy: 0.7272 - aux1_accuracy: 0.7455 - aux2_accuracy: 0.7272 - val_loss: 0.9657 - val_main_loss: 0.6153 - val_aux1_loss: 0.5549 - val_aux2_loss: 0.6134 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.7106 - val_aux2_accuracy: 0.6956\n",
      "Epoch 9/50\n",
      "1120/1120 [==============================] - 49s 44ms/step - loss: 0.9430 - main_loss: 0.6027 - aux1_loss: 0.5490 - aux2_loss: 0.5855 - main_accuracy: 0.7254 - aux1_accuracy: 0.7371 - aux2_accuracy: 0.7272 - val_loss: 0.9967 - val_main_loss: 0.6029 - val_aux1_loss: 0.6376 - val_aux2_loss: 0.6752 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.7025 - val_aux2_accuracy: 0.6574\n",
      "Epoch 10/50\n",
      "1120/1120 [==============================] - 51s 46ms/step - loss: 0.9419 - main_loss: 0.5890 - aux1_loss: 0.5843 - aux2_loss: 0.5921 - main_accuracy: 0.7268 - aux1_accuracy: 0.7308 - aux2_accuracy: 0.7268 - val_loss: 0.9864 - val_main_loss: 0.6126 - val_aux1_loss: 0.6062 - val_aux2_loss: 0.6397 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 11/50\n",
      "1120/1120 [==============================] - 50s 44ms/step - loss: 0.9360 - main_loss: 0.5868 - aux1_loss: 0.5791 - aux2_loss: 0.5849 - main_accuracy: 0.7263 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 1.7584 - val_main_loss: 1.2909 - val_aux1_loss: 0.5758 - val_aux2_loss: 0.9827 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 12/50\n",
      "1120/1120 [==============================] - 51s 46ms/step - loss: 0.9609 - main_loss: 0.6091 - aux1_loss: 0.5828 - aux2_loss: 0.5897 - main_accuracy: 0.7268 - aux1_accuracy: 0.7259 - aux2_accuracy: 0.7268 - val_loss: 0.9836 - val_main_loss: 0.6150 - val_aux1_loss: 0.6095 - val_aux2_loss: 0.6194 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6933 - val_aux2_accuracy: 0.6956\n",
      "Epoch 13/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9428 - main_loss: 0.5892 - aux1_loss: 0.5881 - aux2_loss: 0.5905 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9855 - val_main_loss: 0.6159 - val_aux1_loss: 0.6163 - val_aux2_loss: 0.6158 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 14/50\n",
      "1120/1120 [==============================] - 51s 45ms/step - loss: 0.9546 - main_loss: 0.6022 - aux1_loss: 0.5867 - aux2_loss: 0.5879 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9846 - val_main_loss: 0.6160 - val_aux1_loss: 0.6141 - val_aux2_loss: 0.6147 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 15/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9422 - main_loss: 0.5890 - aux1_loss: 0.5880 - aux2_loss: 0.5891 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 1.0064 - val_main_loss: 0.6301 - val_aux1_loss: 0.6209 - val_aux2_loss: 0.6335 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 16/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9478 - main_loss: 0.5952 - aux1_loss: 0.5868 - aux2_loss: 0.5886 - main_accuracy: 0.7268 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7268 - val_loss: 1.0047 - val_main_loss: 0.6213 - val_aux1_loss: 0.6245 - val_aux2_loss: 0.6536 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 17/50\n",
      "1120/1120 [==============================] - 49s 44ms/step - loss: 0.9414 - main_loss: 0.5884 - aux1_loss: 0.5906 - aux2_loss: 0.5863 - main_accuracy: 0.7272 - aux1_accuracy: 0.7268 - aux2_accuracy: 0.7268 - val_loss: 0.9953 - val_main_loss: 0.6241 - val_aux1_loss: 0.6175 - val_aux2_loss: 0.6199 - val_main_accuracy: 0.6933 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 18/50\n",
      "1120/1120 [==============================] - 49s 44ms/step - loss: 0.9406 - main_loss: 0.5878 - aux1_loss: 0.5896 - aux2_loss: 0.5862 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9874 - val_main_loss: 0.6174 - val_aux1_loss: 0.6167 - val_aux2_loss: 0.6167 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 19/50\n",
      "1120/1120 [==============================] - 49s 44ms/step - loss: 0.9542 - main_loss: 0.6009 - aux1_loss: 0.5886 - aux2_loss: 0.5889 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9890 - val_main_loss: 0.6187 - val_aux1_loss: 0.6175 - val_aux2_loss: 0.6168 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 20/50\n",
      "1120/1120 [==============================] - 49s 44ms/step - loss: 0.9413 - main_loss: 0.5889 - aux1_loss: 0.5869 - aux2_loss: 0.5878 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7259 - val_loss: 0.9844 - val_main_loss: 0.6145 - val_aux1_loss: 0.6171 - val_aux2_loss: 0.6159 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 21/50\n",
      "1120/1120 [==============================] - 49s 44ms/step - loss: 0.9393 - main_loss: 0.5866 - aux1_loss: 0.5884 - aux2_loss: 0.5874 - main_accuracy: 0.7272 - aux1_accuracy: 0.7268 - aux2_accuracy: 0.7272 - val_loss: 0.9966 - val_main_loss: 0.6274 - val_aux1_loss: 0.6173 - val_aux2_loss: 0.6134 - val_main_accuracy: 0.6933 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 22/50\n",
      "1120/1120 [==============================] - 50s 44ms/step - loss: 0.9397 - main_loss: 0.5873 - aux1_loss: 0.5872 - aux2_loss: 0.5873 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9886 - val_main_loss: 0.6185 - val_aux1_loss: 0.6165 - val_aux2_loss: 0.6170 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 23/50\n",
      "1120/1120 [==============================] - 49s 44ms/step - loss: 0.9396 - main_loss: 0.5871 - aux1_loss: 0.5872 - aux2_loss: 0.5880 - main_accuracy: 0.7268 - aux1_accuracy: 0.7263 - aux2_accuracy: 0.7272 - val_loss: 0.9837 - val_main_loss: 0.6139 - val_aux1_loss: 0.6173 - val_aux2_loss: 0.6155 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 24/50\n",
      "1120/1120 [==============================] - 50s 44ms/step - loss: 0.9412 - main_loss: 0.5891 - aux1_loss: 0.5864 - aux2_loss: 0.5871 - main_accuracy: 0.7268 - aux1_accuracy: 0.7254 - aux2_accuracy: 0.7272 - val_loss: 0.9913 - val_main_loss: 0.6211 - val_aux1_loss: 0.6170 - val_aux2_loss: 0.6167 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 25/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9457 - main_loss: 0.5949 - aux1_loss: 0.5851 - aux2_loss: 0.5845 - main_accuracy: 0.7254 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9843 - val_main_loss: 0.6158 - val_aux1_loss: 0.6142 - val_aux2_loss: 0.6141 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 26/50\n",
      "1120/1120 [==============================] - 50s 44ms/step - loss: 0.9386 - main_loss: 0.5863 - aux1_loss: 0.5865 - aux2_loss: 0.5877 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7268 - val_loss: 0.9787 - val_main_loss: 0.6120 - val_aux1_loss: 0.6101 - val_aux2_loss: 0.6124 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 27/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9347 - main_loss: 0.5864 - aux1_loss: 0.5769 - aux2_loss: 0.5841 - main_accuracy: 0.7272 - aux1_accuracy: 0.7277 - aux2_accuracy: 0.7272 - val_loss: 0.9595 - val_main_loss: 0.6033 - val_aux1_loss: 0.5821 - val_aux2_loss: 0.6053 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.7234 - val_aux2_accuracy: 0.6956\n",
      "Epoch 28/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9338 - main_loss: 0.5857 - aux1_loss: 0.5764 - aux2_loss: 0.5840 - main_accuracy: 0.7272 - aux1_accuracy: 0.7192 - aux2_accuracy: 0.7272 - val_loss: 0.9669 - val_main_loss: 0.6120 - val_aux1_loss: 0.5779 - val_aux2_loss: 0.6049 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 29/50\n",
      "1120/1120 [==============================] - 50s 44ms/step - loss: 0.9448 - main_loss: 0.5944 - aux1_loss: 0.5802 - aux2_loss: 0.5877 - main_accuracy: 0.7268 - aux1_accuracy: 0.7290 - aux2_accuracy: 0.7272 - val_loss: 0.9908 - val_main_loss: 0.6174 - val_aux1_loss: 0.6287 - val_aux2_loss: 0.6160 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 30/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9463 - main_loss: 0.5943 - aux1_loss: 0.5876 - aux2_loss: 0.5857 - main_accuracy: 0.7268 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9808 - val_main_loss: 0.6143 - val_aux1_loss: 0.6158 - val_aux2_loss: 0.6061 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 31/50\n",
      "1120/1120 [==============================] - 50s 44ms/step - loss: 0.9435 - main_loss: 0.5918 - aux1_loss: 0.5862 - aux2_loss: 0.5862 - main_accuracy: 0.7259 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9847 - val_main_loss: 0.6146 - val_aux1_loss: 0.6174 - val_aux2_loss: 0.6162 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 32/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9416 - main_loss: 0.5893 - aux1_loss: 0.5872 - aux2_loss: 0.5870 - main_accuracy: 0.7259 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9863 - val_main_loss: 0.6164 - val_aux1_loss: 0.6155 - val_aux2_loss: 0.6175 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 33/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9388 - main_loss: 0.5867 - aux1_loss: 0.5868 - aux2_loss: 0.5869 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9877 - val_main_loss: 0.6170 - val_aux1_loss: 0.6181 - val_aux2_loss: 0.6174 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 34/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9466 - main_loss: 0.5952 - aux1_loss: 0.5858 - aux2_loss: 0.5857 - main_accuracy: 0.7259 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9819 - val_main_loss: 0.6162 - val_aux1_loss: 0.6076 - val_aux2_loss: 0.6114 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 35/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9391 - main_loss: 0.5871 - aux1_loss: 0.5859 - aux2_loss: 0.5873 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9841 - val_main_loss: 0.6164 - val_aux1_loss: 0.6090 - val_aux2_loss: 0.6165 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 36/50\n",
      "1120/1120 [==============================] - 51s 46ms/step - loss: 0.9379 - main_loss: 0.5863 - aux1_loss: 0.5856 - aux2_loss: 0.5864 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9852 - val_main_loss: 0.6160 - val_aux1_loss: 0.6142 - val_aux2_loss: 0.6164 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 37/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9378 - main_loss: 0.5865 - aux1_loss: 0.5849 - aux2_loss: 0.5863 - main_accuracy: 0.7272 - aux1_accuracy: 0.7263 - aux2_accuracy: 0.7272 - val_loss: 0.9845 - val_main_loss: 0.6158 - val_aux1_loss: 0.6126 - val_aux2_loss: 0.6163 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 38/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9388 - main_loss: 0.5878 - aux1_loss: 0.5840 - aux2_loss: 0.5861 - main_accuracy: 0.7263 - aux1_accuracy: 0.7263 - aux2_accuracy: 0.7272 - val_loss: 0.9874 - val_main_loss: 0.6178 - val_aux1_loss: 0.6167 - val_aux2_loss: 0.6155 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 39/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9396 - main_loss: 0.5877 - aux1_loss: 0.5856 - aux2_loss: 0.5875 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7268 - val_loss: 0.9896 - val_main_loss: 0.6236 - val_aux1_loss: 0.6010 - val_aux2_loss: 0.6190 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 40/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9372 - main_loss: 0.5881 - aux1_loss: 0.5782 - aux2_loss: 0.5854 - main_accuracy: 0.7272 - aux1_accuracy: 0.7277 - aux2_accuracy: 0.7272 - val_loss: 0.9776 - val_main_loss: 0.6180 - val_aux1_loss: 0.5787 - val_aux2_loss: 0.6199 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.7222 - val_aux2_accuracy: 0.6956\n",
      "Epoch 41/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9378 - main_loss: 0.5870 - aux1_loss: 0.5832 - aux2_loss: 0.5862 - main_accuracy: 0.7272 - aux1_accuracy: 0.7241 - aux2_accuracy: 0.7272 - val_loss: 0.9813 - val_main_loss: 0.6170 - val_aux1_loss: 0.6009 - val_aux2_loss: 0.6133 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 42/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9360 - main_loss: 0.5866 - aux1_loss: 0.5791 - aux2_loss: 0.5854 - main_accuracy: 0.7272 - aux1_accuracy: 0.7210 - aux2_accuracy: 0.7272 - val_loss: 0.9862 - val_main_loss: 0.6173 - val_aux1_loss: 0.6034 - val_aux2_loss: 0.6262 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 43/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9397 - main_loss: 0.5886 - aux1_loss: 0.5829 - aux2_loss: 0.5875 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9852 - val_main_loss: 0.6164 - val_aux1_loss: 0.6099 - val_aux2_loss: 0.6195 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6944\n",
      "Epoch 44/50\n",
      "1120/1120 [==============================] - 51s 45ms/step - loss: 0.9511 - main_loss: 0.5980 - aux1_loss: 0.5893 - aux2_loss: 0.5876 - main_accuracy: 0.7272 - aux1_accuracy: 0.7268 - aux2_accuracy: 0.7272 - val_loss: 0.9877 - val_main_loss: 0.6175 - val_aux1_loss: 0.6179 - val_aux2_loss: 0.6162 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6944\n",
      "Epoch 45/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9376 - main_loss: 0.5865 - aux1_loss: 0.5848 - aux2_loss: 0.5857 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9909 - val_main_loss: 0.6189 - val_aux1_loss: 0.6205 - val_aux2_loss: 0.6196 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 46/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9375 - main_loss: 0.5862 - aux1_loss: 0.5842 - aux2_loss: 0.5869 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9854 - val_main_loss: 0.6160 - val_aux1_loss: 0.6153 - val_aux2_loss: 0.6159 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 47/50\n",
      "1120/1120 [==============================] - 52901s 47s/step - loss: 0.9373 - main_loss: 0.5863 - aux1_loss: 0.5838 - aux2_loss: 0.5863 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9873 - val_main_loss: 0.6170 - val_aux1_loss: 0.6175 - val_aux2_loss: 0.6169 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 48/50\n",
      "1120/1120 [==============================] - 56s 50ms/step - loss: 0.9378 - main_loss: 0.5862 - aux1_loss: 0.5856 - aux2_loss: 0.5862 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9865 - val_main_loss: 0.6170 - val_aux1_loss: 0.6147 - val_aux2_loss: 0.6170 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 49/50\n",
      "1120/1120 [==============================] - 52s 46ms/step - loss: 0.9386 - main_loss: 0.5868 - aux1_loss: 0.5863 - aux2_loss: 0.5863 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9866 - val_main_loss: 0.6171 - val_aux1_loss: 0.6096 - val_aux2_loss: 0.6221 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 50/50\n",
      "1120/1120 [==============================] - 52s 47ms/step - loss: 0.9388 - main_loss: 0.5869 - aux1_loss: 0.5869 - aux2_loss: 0.5864 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9847 - val_main_loss: 0.6169 - val_aux1_loss: 0.6094 - val_aux2_loss: 0.6166 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Usnig optimizer: SGD, Epoch: 50\n",
      "Epoch 1/50\n",
      "1120/1120 [==============================] - 53s 43ms/step - loss: 0.9371 - main_loss: 0.5869 - aux1_loss: 0.5809 - aux2_loss: 0.5863 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9838 - val_main_loss: 0.6165 - val_aux1_loss: 0.6087 - val_aux2_loss: 0.6157 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 2/50\n",
      "1120/1120 [==============================] - 47s 42ms/step - loss: 0.9360 - main_loss: 0.5868 - aux1_loss: 0.5780 - aux2_loss: 0.5862 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9827 - val_main_loss: 0.6159 - val_aux1_loss: 0.6076 - val_aux2_loss: 0.6150 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 3/50\n",
      "1120/1120 [==============================] - 49s 44ms/step - loss: 0.9370 - main_loss: 0.5865 - aux1_loss: 0.5821 - aux2_loss: 0.5862 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9823 - val_main_loss: 0.6156 - val_aux1_loss: 0.6072 - val_aux2_loss: 0.6152 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 4/50\n",
      "1120/1120 [==============================] - 50s 45ms/step - loss: 0.9371 - main_loss: 0.5868 - aux1_loss: 0.5812 - aux2_loss: 0.5863 - main_accuracy: 0.7272 - aux1_accuracy: 0.7272 - aux2_accuracy: 0.7272 - val_loss: 0.9830 - val_main_loss: 0.6165 - val_aux1_loss: 0.6055 - val_aux2_loss: 0.6163 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 5/50\n",
      "1120/1120 [==============================] - 56s 50ms/step - loss: 0.9361 - main_loss: 0.5868 - aux1_loss: 0.5782 - aux2_loss: 0.5863 - main_accuracy: 0.7272 - aux1_accuracy: 0.7268 - aux2_accuracy: 0.7272 - val_loss: 0.9855 - val_main_loss: 0.6186 - val_aux1_loss: 0.6069 - val_aux2_loss: 0.6161 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 6/50\n",
      "1120/1120 [==============================] - 49s 44ms/step - loss: 0.9369 - main_loss: 0.5868 - aux1_loss: 0.5807 - aux2_loss: 0.5863 - main_accuracy: 0.7272 - aux1_accuracy: 0.7263 - aux2_accuracy: 0.7272 - val_loss: 0.9845 - val_main_loss: 0.6181 - val_aux1_loss: 0.6065 - val_aux2_loss: 0.6149 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 7/50\n",
      "1120/1120 [==============================] - 46s 41ms/step - loss: 0.9357 - main_loss: 0.5866 - aux1_loss: 0.5776 - aux2_loss: 0.5862 - main_accuracy: 0.7272 - aux1_accuracy: 0.7268 - aux2_accuracy: 0.7272 - val_loss: 0.9850 - val_main_loss: 0.6191 - val_aux1_loss: 0.6045 - val_aux2_loss: 0.6153 - val_main_accuracy: 0.6956 - val_aux1_accuracy: 0.6956 - val_aux2_accuracy: 0.6956\n",
      "Epoch 8/50\n",
      " 703/1120 [=================>............] - ETA: 16s - loss: 0.9133 - main_loss: 0.5727 - aux1_loss: 0.5631 - aux2_loss: 0.5723 - main_accuracy: 0.7411 - aux1_accuracy: 0.7411 - aux2_accuracy: 0.7411"
     ]
    }
   ],
   "source": [
    "optimizer = ['Adam', 'SGD', 'Adam', 'SGD']\n",
    "epochs = [50,50,50,50]\n",
    "history_all = {}\n",
    "\n",
    "for i in range(len(optimizer)):\n",
    "    print('Usnig optimizer: ' + optimizer[i] + ', Epoch: ' + str(epochs[i]))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  loss_weights={'main': 1.0,'aux1': 0.3, 'aux2': 0.3},\n",
    "                  optimizer=optimizer[i], metrics=['accuracy'])\n",
    "    \n",
    "    train_history = model.fit(X_train, \n",
    "                              y_train_one_hot, \n",
    "                              steps_per_epoch=EPOCH_STEPS, \n",
    "                              epochs=epochs[i], shuffle=True, \n",
    "                              validation_data=(X_val, y_val_one_hot))\n",
    "    \n",
    "    # save history    \n",
    "    if len(history_all) == 0:\n",
    "        history_all = {key: [] for key in train_history.history}\n",
    "    \n",
    "    for key in history_all:\n",
    "        history_all[key].extend(train_history.history[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d7b43a-2124-4a56-b0e7-a08b53161002",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = r\"D:\\PCOS_Challenge\\Test_model\"\n",
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649f175f-6881-4994-b64a-7528497149a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show train history\n",
    "def show_train_history(history, xlabel, ylabel, train):\n",
    "    for item in train:\n",
    "        plt.plot(history[item])\n",
    "    plt.title('Train History')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend(train, loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "show_train_history(history_all, 'Epoch', 'Accuracy', ('main_accuracy', 'aux1_accuracy', 'aux2_accuracy'))\n",
    "show_train_history(history_all, 'Epoch', 'Loss', ('main_loss', 'aux1_loss', 'aux2_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a7f519-2d9b-4417-bda5-690182ff3750",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get model predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# If your predictions are one-hot encoded, convert them to integer labels\n",
    "predicted_labels = np.argmax(predictions[1], axis=1)\n",
    "\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9c410-9caa-4dfd-8502-1e81a4d877bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cab474-895d-47ea-ba9d-b0fc2279e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_test_one_hot = to_categorical(y_test_encoded)\n",
    "\n",
    "# Assuming y_test_one_hot is a one-hot encoded array\n",
    "y_true = np.argmax(y_test_one_hot, axis=1)\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_true, predicted_labels)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c37cf-3a05-446e-80e2-a7e028281a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "325ba502-0a88-4623-812a-ec1470c84cb4",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d64f89d-1df3-49c1-85ce-0e41c0f59aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\functional.py:156: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "MODEL_NAME = r\"D:\\PCOS_Challenge\\Test_model\"\n",
    "model = load_model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddcd49d3-0adf-4dd6-8996-43faa6aabd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Testing\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "test_path = r\"D:\\PCOS_Challenge\\Test data\\images\"\n",
    "images =[]\n",
    "image_path =[]\n",
    "for finename in os.listdir(test_path):\n",
    "    img_path = os.path.join(test_path, finename)\n",
    "    image_path.append(img_path)\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((128, 128))\n",
    "    img = img.convert(\"L\")\n",
    "    img_array = np.array(img)\n",
    "    images.append(img_array)\n",
    "    \n",
    "test_images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7425c902-822e-47db-ba1c-3247376dd5e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  2,   3,   3, ...,   3,   3,   1],\n",
       "        [  1,   0,  11, ...,  26,  16,   6],\n",
       "        [  4,   2,  24, ...,  41,  20,  13],\n",
       "        ...,\n",
       "        [  1,   1,   1, ...,   3,   3,   3],\n",
       "        [  1,   1,   1, ...,   3,   3,   3],\n",
       "        [  1,   1,   1, ...,   3,   3,   3]],\n",
       "\n",
       "       [[  1,   1,   1, ..., 205, 179,  97],\n",
       "        [  1,   1,   1, ..., 134,  72,  19],\n",
       "        [  1,   1,   1, ...,  18,  11,   6],\n",
       "        ...,\n",
       "        [  1,   1,   1, ...,   1,   1,   1],\n",
       "        [  1,   1,   1, ...,   1,   1,   1],\n",
       "        [  1,   1,   1, ...,   1,   1,   1]],\n",
       "\n",
       "       [[  7,   7,   7, ...,   7,   7,   7],\n",
       "        [  7,   7,   7, ...,   7,   7,   7],\n",
       "        [  7,   7,   7, ...,   7,   7,   7],\n",
       "        ...,\n",
       "        [  7,   7,   7, ...,   5,   8,   8],\n",
       "        [  7,   7,   7, ...,  10,  14,   9],\n",
       "        [  7,   7,   7, ...,   7,  10,   6]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 48,  48,  49, ...,  35,  34,  31],\n",
       "        [ 48,  47,  48, ...,  35,  34,  31],\n",
       "        [ 47,  46,  48, ...,  35,  34,  31],\n",
       "        ...,\n",
       "        [ 53,  53,  55, ...,  73,  75,  60],\n",
       "        [ 53,  52,  53, ...,  69,  73,  60],\n",
       "        [ 51,  50,  51, ...,  65,  70,  59]],\n",
       "\n",
       "       [[  4,   3,   2, ...,   0,   0,   0],\n",
       "        [  3,   2,   2, ...,   0,   0,   0],\n",
       "        [  2,   2,   1, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [  2,   3,   5, ...,  29,  32,  39],\n",
       "        [  0,   1,   5, ...,  24,  36,  42],\n",
       "        [  0,   0,   4, ...,  38,  45,  47]],\n",
       "\n",
       "       [[ 11,   9,  10, ...,  11,  11,  11],\n",
       "        [ 11,   9,  10, ...,  11,  11,  11],\n",
       "        [ 11,   9,  10, ...,  11,  11,  11],\n",
       "        ...,\n",
       "        [ 15,  13,  11, ...,  74,  65,  58],\n",
       "        [ 15,  13,  13, ..., 106,  87,  74],\n",
       "        [ 15,  14,  14, ..., 126, 108,  94]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6244fcb0-74ae-4c00-9ae8-fae1e3778b2e",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f7b284a-4495-4d90-a7e2-3d03057b804d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 4s 70ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_pred = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1207a25e-11f3-4984-aecd-c68ca01c4ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28200927, 0.7179907 ],\n",
       "       [0.28200927, 0.7179907 ],\n",
       "       [0.28200927, 0.7179907 ],\n",
       "       ...,\n",
       "       [0.28200927, 0.7179907 ],\n",
       "       [0.28200927, 0.7179907 ],\n",
       "       [0.28200927, 0.7179907 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68ca2c38-fab0-4e57-967b-5b508fa5e854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_predicted_labels = np.argmax(test_pred[0], axis=1)\n",
    "\n",
    "test_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb30d1e3-129e-45eb-9aaf-bfe4551fdb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path =[]\n",
    "for path in image_path:\n",
    "    p = path.split('\\\\')\n",
    "    #print(p[-1])\n",
    "    img_path.append(p[-1])\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a0f1b92-c8b0-4e08-8ace-c9a1a5197597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image10000.jpg',\n",
       " 'image10001.jpg',\n",
       " 'image10002.jpg',\n",
       " 'image10003.jpg',\n",
       " 'image10004.jpg',\n",
       " 'image10005.jpg',\n",
       " 'image10006.jpg',\n",
       " 'image10007.jpg',\n",
       " 'image10008.jpg',\n",
       " 'image10009.jpg',\n",
       " 'image10010.jpg',\n",
       " 'image10011.jpg',\n",
       " 'image10012.jpg',\n",
       " 'image10013.jpg',\n",
       " 'image10014.jpg',\n",
       " 'image10015.jpg',\n",
       " 'image10016.jpg',\n",
       " 'image10017.jpg',\n",
       " 'image10018.jpg',\n",
       " 'image10019.jpg',\n",
       " 'image10020.jpg',\n",
       " 'image10021.jpg',\n",
       " 'image10022.jpg',\n",
       " 'image10023.jpg',\n",
       " 'image10024.jpg',\n",
       " 'image10025.jpg',\n",
       " 'image10026.jpg',\n",
       " 'image10027.jpg',\n",
       " 'image10028.jpg',\n",
       " 'image10029.jpg',\n",
       " 'image10030.jpg',\n",
       " 'image10031.jpg',\n",
       " 'image10032.jpg',\n",
       " 'image10033.jpg',\n",
       " 'image10034.jpg',\n",
       " 'image10035.jpg',\n",
       " 'image10036.jpg',\n",
       " 'image10037.jpg',\n",
       " 'image10038.jpg',\n",
       " 'image10039.jpg',\n",
       " 'image10040.jpg',\n",
       " 'image10041.jpg',\n",
       " 'image10042.jpg',\n",
       " 'image10043.jpg',\n",
       " 'image10044.jpg',\n",
       " 'image10045.jpg',\n",
       " 'image10046.jpg',\n",
       " 'image10047.jpg',\n",
       " 'image10048.jpg',\n",
       " 'image10049.jpg',\n",
       " 'image10050.jpg',\n",
       " 'image10051.jpg',\n",
       " 'image10052.jpg',\n",
       " 'image10053.jpg',\n",
       " 'image10054.jpg',\n",
       " 'image10055.jpg',\n",
       " 'image10056.jpg',\n",
       " 'image10057.jpg',\n",
       " 'image10058.jpg',\n",
       " 'image10059.jpg',\n",
       " 'image10060.jpg',\n",
       " 'image10061.jpg',\n",
       " 'image10062.jpg',\n",
       " 'image10063.jpg',\n",
       " 'image10064.jpg',\n",
       " 'image10065.jpg',\n",
       " 'image10066.jpg',\n",
       " 'image10067.jpg',\n",
       " 'image10068.jpg',\n",
       " 'image10069.jpg',\n",
       " 'image10070.jpg',\n",
       " 'image10071.jpg',\n",
       " 'image10072.jpg',\n",
       " 'image10073.jpg',\n",
       " 'image10074.jpg',\n",
       " 'image10075.jpg',\n",
       " 'image10076.jpg',\n",
       " 'image10077.jpg',\n",
       " 'image10078.jpg',\n",
       " 'image10079.jpg',\n",
       " 'image10080.jpg',\n",
       " 'image10081.jpg',\n",
       " 'image10082.jpg',\n",
       " 'image10083.jpg',\n",
       " 'image10084.jpg',\n",
       " 'image10085.jpg',\n",
       " 'image10086.jpg',\n",
       " 'image10087.jpg',\n",
       " 'image10088.jpg',\n",
       " 'image10089.jpg',\n",
       " 'image10090.jpg',\n",
       " 'image10091.jpg',\n",
       " 'image10092.jpg',\n",
       " 'image10093.jpg',\n",
       " 'image10094.jpg',\n",
       " 'image10095.jpg',\n",
       " 'image10096.jpg',\n",
       " 'image10097.jpg',\n",
       " 'image10098.jpg',\n",
       " 'image10099.jpg',\n",
       " 'image10100.jpg',\n",
       " 'image10101.jpg',\n",
       " 'image10102.jpg',\n",
       " 'image10103.jpg',\n",
       " 'image10104.jpg',\n",
       " 'image10105.jpg',\n",
       " 'image10106.jpg',\n",
       " 'image10107.jpg',\n",
       " 'image10108.jpg',\n",
       " 'image10109.jpg',\n",
       " 'image10110.jpg',\n",
       " 'image10111.jpg',\n",
       " 'image10112.jpg',\n",
       " 'image10113.jpg',\n",
       " 'image10114.jpg',\n",
       " 'image10115.jpg',\n",
       " 'image10116.jpg',\n",
       " 'image10117.jpg',\n",
       " 'image10118.jpg',\n",
       " 'image10119.jpg',\n",
       " 'image10120.jpg',\n",
       " 'image10121.jpg',\n",
       " 'image10122.jpg',\n",
       " 'image10123.jpg',\n",
       " 'image10124.jpg',\n",
       " 'image10125.jpg',\n",
       " 'image10126.jpg',\n",
       " 'image10127.jpg',\n",
       " 'image10128.jpg',\n",
       " 'image10129.jpg',\n",
       " 'image10130.jpg',\n",
       " 'image10131.jpg',\n",
       " 'image10132.jpg',\n",
       " 'image10133.jpg',\n",
       " 'image10134.jpg',\n",
       " 'image10135.jpg',\n",
       " 'image10136.jpg',\n",
       " 'image10137.jpg',\n",
       " 'image10138.jpg',\n",
       " 'image10139.jpg',\n",
       " 'image10140.jpg',\n",
       " 'image10141.jpg',\n",
       " 'image10142.jpg',\n",
       " 'image10143.jpg',\n",
       " 'image10144.jpg',\n",
       " 'image10145.jpg',\n",
       " 'image10146.jpg',\n",
       " 'image10147.jpg',\n",
       " 'image10148.jpg',\n",
       " 'image10149.jpg',\n",
       " 'image10150.jpg',\n",
       " 'image10151.jpg',\n",
       " 'image10152.jpg',\n",
       " 'image10153.jpg',\n",
       " 'image10154.jpg',\n",
       " 'image10155.jpg',\n",
       " 'image10156.jpg',\n",
       " 'image10157.jpg',\n",
       " 'image10158.jpg',\n",
       " 'image10159.jpg',\n",
       " 'image10160.jpg',\n",
       " 'image10161.jpg',\n",
       " 'image10162.jpg',\n",
       " 'image10163.jpg',\n",
       " 'image10164.jpg',\n",
       " 'image10165.jpg',\n",
       " 'image10166.jpg',\n",
       " 'image10167.jpg',\n",
       " 'image10168.jpg',\n",
       " 'image10169.jpg',\n",
       " 'image10170.jpg',\n",
       " 'image10171.jpg',\n",
       " 'image10172.jpg',\n",
       " 'image10173.jpg',\n",
       " 'image10174.jpg',\n",
       " 'image10175.jpg',\n",
       " 'image10176.jpg',\n",
       " 'image10177.jpg',\n",
       " 'image10178.jpg',\n",
       " 'image10179.jpg',\n",
       " 'image10180.jpg',\n",
       " 'image10181.jpg',\n",
       " 'image10182.jpg',\n",
       " 'image10183.jpg',\n",
       " 'image10184.jpg',\n",
       " 'image10185.jpg',\n",
       " 'image10186.jpg',\n",
       " 'image10187.jpg',\n",
       " 'image10188.jpg',\n",
       " 'image10189.jpg',\n",
       " 'image10190.jpg',\n",
       " 'image10191.jpg',\n",
       " 'image10192.jpg',\n",
       " 'image10193.jpg',\n",
       " 'image10194.jpg',\n",
       " 'image10195.jpg',\n",
       " 'image10196.jpg',\n",
       " 'image10197.jpg',\n",
       " 'image10198.jpg',\n",
       " 'image10199.jpg',\n",
       " 'image10200.jpg',\n",
       " 'image10201.jpg',\n",
       " 'image10202.jpg',\n",
       " 'image10203.jpg',\n",
       " 'image10204.jpg',\n",
       " 'image10205.jpg',\n",
       " 'image10206.jpg',\n",
       " 'image10207.jpg',\n",
       " 'image10208.jpg',\n",
       " 'image10209.jpg',\n",
       " 'image10210.jpg',\n",
       " 'image10211.jpg',\n",
       " 'image10212.jpg',\n",
       " 'image10213.jpg',\n",
       " 'image10214.jpg',\n",
       " 'image10215.jpg',\n",
       " 'image10216.jpg',\n",
       " 'image10217.jpg',\n",
       " 'image10218.jpg',\n",
       " 'image10219.jpg',\n",
       " 'image10220.jpg',\n",
       " 'image10221.jpg',\n",
       " 'image10222.jpg',\n",
       " 'image10223.jpg',\n",
       " 'image10224.jpg',\n",
       " 'image10225.jpg',\n",
       " 'image10226.jpg',\n",
       " 'image10227.jpg',\n",
       " 'image10228.jpg',\n",
       " 'image10229.jpg',\n",
       " 'image10230.jpg',\n",
       " 'image10231.jpg',\n",
       " 'image10232.jpg',\n",
       " 'image10233.jpg',\n",
       " 'image10234.jpg',\n",
       " 'image10235.jpg',\n",
       " 'image10236.jpg',\n",
       " 'image10237.jpg',\n",
       " 'image10238.jpg',\n",
       " 'image10239.jpg',\n",
       " 'image10240.jpg',\n",
       " 'image10241.jpg',\n",
       " 'image10242.jpg',\n",
       " 'image10243.jpg',\n",
       " 'image10244.jpg',\n",
       " 'image10245.jpg',\n",
       " 'image10246.jpg',\n",
       " 'image10247.jpg',\n",
       " 'image10248.jpg',\n",
       " 'image10249.jpg',\n",
       " 'image10250.jpg',\n",
       " 'image10251.jpg',\n",
       " 'image10252.jpg',\n",
       " 'image10253.jpg',\n",
       " 'image10254.jpg',\n",
       " 'image10255.jpg',\n",
       " 'image10256.jpg',\n",
       " 'image10257.jpg',\n",
       " 'image10258.jpg',\n",
       " 'image10259.jpg',\n",
       " 'image10260.jpg',\n",
       " 'image10261.jpg',\n",
       " 'image10262.jpg',\n",
       " 'image10263.jpg',\n",
       " 'image10264.jpg',\n",
       " 'image10265.jpg',\n",
       " 'image10266.jpg',\n",
       " 'image10267.jpg',\n",
       " 'image10268.jpg',\n",
       " 'image10269.jpg',\n",
       " 'image10270.jpg',\n",
       " 'image10271.jpg',\n",
       " 'image10272.jpg',\n",
       " 'image10273.jpg',\n",
       " 'image10274.jpg',\n",
       " 'image10275.jpg',\n",
       " 'image10276.jpg',\n",
       " 'image10277.jpg',\n",
       " 'image10278.jpg',\n",
       " 'image10279.jpg',\n",
       " 'image10280.jpg',\n",
       " 'image10281.jpg',\n",
       " 'image10282.jpg',\n",
       " 'image10283.jpg',\n",
       " 'image10284.jpg',\n",
       " 'image10285.jpg',\n",
       " 'image10286.jpg',\n",
       " 'image10287.jpg',\n",
       " 'image10288.jpg',\n",
       " 'image10289.jpg',\n",
       " 'image10290.jpg',\n",
       " 'image10291.jpg',\n",
       " 'image10292.jpg',\n",
       " 'image10293.jpg',\n",
       " 'image10294.jpg',\n",
       " 'image10295.jpg',\n",
       " 'image10296.jpg',\n",
       " 'image10297.jpg',\n",
       " 'image10298.jpg',\n",
       " 'image10299.jpg',\n",
       " 'image10300.jpg',\n",
       " 'image10301.jpg',\n",
       " 'image10302.jpg',\n",
       " 'image10303.jpg',\n",
       " 'image10304.jpg',\n",
       " 'image10305.jpg',\n",
       " 'image10306.jpg',\n",
       " 'image10307.jpg',\n",
       " 'image10308.jpg',\n",
       " 'image10309.jpg',\n",
       " 'image10310.jpg',\n",
       " 'image10311.jpg',\n",
       " 'image10312.jpg',\n",
       " 'image10313.jpg',\n",
       " 'image10314.jpg',\n",
       " 'image10315.jpg',\n",
       " 'image10316.jpg',\n",
       " 'image10317.jpg',\n",
       " 'image10318.jpg',\n",
       " 'image10319.jpg',\n",
       " 'image10320.jpg',\n",
       " 'image10321.jpg',\n",
       " 'image10322.jpg',\n",
       " 'image10323.jpg',\n",
       " 'image10324.jpg',\n",
       " 'image10325.jpg',\n",
       " 'image10326.jpg',\n",
       " 'image10327.jpg',\n",
       " 'image10328.jpg',\n",
       " 'image10329.jpg',\n",
       " 'image10330.jpg',\n",
       " 'image10331.jpg',\n",
       " 'image10332.jpg',\n",
       " 'image10333.jpg',\n",
       " 'image10334.jpg',\n",
       " 'image10335.jpg',\n",
       " 'image10336.jpg',\n",
       " 'image10337.jpg',\n",
       " 'image10338.jpg',\n",
       " 'image10339.jpg',\n",
       " 'image10340.jpg',\n",
       " 'image10341.jpg',\n",
       " 'image10342.jpg',\n",
       " 'image10343.jpg',\n",
       " 'image10344.jpg',\n",
       " 'image10345.jpg',\n",
       " 'image10346.jpg',\n",
       " 'image10347.jpg',\n",
       " 'image10348.jpg',\n",
       " 'image10349.jpg',\n",
       " 'image10350.jpg',\n",
       " 'image10351.jpg',\n",
       " 'image10352.jpg',\n",
       " 'image10353.jpg',\n",
       " 'image10354.jpg',\n",
       " 'image10355.jpg',\n",
       " 'image10356.jpg',\n",
       " 'image10357.jpg',\n",
       " 'image10358.jpg',\n",
       " 'image10359.jpg',\n",
       " 'image10360.jpg',\n",
       " 'image10361.jpg',\n",
       " 'image10362.jpg',\n",
       " 'image10363.jpg',\n",
       " 'image10364.jpg',\n",
       " 'image10365.jpg',\n",
       " 'image10366.jpg',\n",
       " 'image10367.jpg',\n",
       " 'image10368.jpg',\n",
       " 'image10369.jpg',\n",
       " 'image10370.jpg',\n",
       " 'image10371.jpg',\n",
       " 'image10372.jpg',\n",
       " 'image10373.jpg',\n",
       " 'image10374.jpg',\n",
       " 'image10375.jpg',\n",
       " 'image10376.jpg',\n",
       " 'image10377.jpg',\n",
       " 'image10378.jpg',\n",
       " 'image10379.jpg',\n",
       " 'image10380.jpg',\n",
       " 'image10381.jpg',\n",
       " 'image10382.jpg',\n",
       " 'image10383.jpg',\n",
       " 'image10384.jpg',\n",
       " 'image10385.jpg',\n",
       " 'image10386.jpg',\n",
       " 'image10387.jpg',\n",
       " 'image10388.jpg',\n",
       " 'image10389.jpg',\n",
       " 'image10390.jpg',\n",
       " 'image10391.jpg',\n",
       " 'image10392.jpg',\n",
       " 'image10393.jpg',\n",
       " 'image10394.jpg',\n",
       " 'image10395.jpg',\n",
       " 'image10396.jpg',\n",
       " 'image10397.jpg',\n",
       " 'image10398.jpg',\n",
       " 'image10399.jpg',\n",
       " 'image10400.jpg',\n",
       " 'image10401.jpg',\n",
       " 'image10402.jpg',\n",
       " 'image10403.jpg',\n",
       " 'image10404.jpg',\n",
       " 'image10405.jpg',\n",
       " 'image10406.jpg',\n",
       " 'image10407.jpg',\n",
       " 'image10408.jpg',\n",
       " 'image10409.jpg',\n",
       " 'image10410.jpg',\n",
       " 'image10411.jpg',\n",
       " 'image10412.jpg',\n",
       " 'image10413.jpg',\n",
       " 'image10414.jpg',\n",
       " 'image10415.jpg',\n",
       " 'image10416.jpg',\n",
       " 'image10417.jpg',\n",
       " 'image10418.jpg',\n",
       " 'image10419.jpg',\n",
       " 'image10420.jpg',\n",
       " 'image10421.jpg',\n",
       " 'image10422.jpg',\n",
       " 'image10423.jpg',\n",
       " 'image10424.jpg',\n",
       " 'image10425.jpg',\n",
       " 'image10426.jpg',\n",
       " 'image10427.jpg',\n",
       " 'image10428.jpg',\n",
       " 'image10429.jpg',\n",
       " 'image10430.jpg',\n",
       " 'image10431.jpg',\n",
       " 'image10432.jpg',\n",
       " 'image10433.jpg',\n",
       " 'image10434.jpg',\n",
       " 'image10435.jpg',\n",
       " 'image10436.jpg',\n",
       " 'image10437.jpg',\n",
       " 'image10438.jpg',\n",
       " 'image10439.jpg',\n",
       " 'image10440.jpg',\n",
       " 'image10441.jpg',\n",
       " 'image10442.jpg',\n",
       " 'image10443.jpg',\n",
       " 'image10444.jpg',\n",
       " 'image10445.jpg',\n",
       " 'image10446.jpg',\n",
       " 'image10447.jpg',\n",
       " 'image10448.jpg',\n",
       " 'image10449.jpg',\n",
       " 'image10450.jpg',\n",
       " 'image10451.jpg',\n",
       " 'image10452.jpg',\n",
       " 'image10453.jpg',\n",
       " 'image10454.jpg',\n",
       " 'image10455.jpg',\n",
       " 'image10456.jpg',\n",
       " 'image10457.jpg',\n",
       " 'image10458.jpg',\n",
       " 'image10459.jpg',\n",
       " 'image10460.jpg',\n",
       " 'image10461.jpg',\n",
       " 'image10462.jpg',\n",
       " 'image10463.jpg',\n",
       " 'image10464.jpg',\n",
       " 'image10465.jpg',\n",
       " 'image10466.jpg',\n",
       " 'image10467.jpg',\n",
       " 'image10468.jpg',\n",
       " 'image10469.jpg',\n",
       " 'image10470.jpg',\n",
       " 'image10471.jpg',\n",
       " 'image10472.jpg',\n",
       " 'image10473.jpg',\n",
       " 'image10474.jpg',\n",
       " 'image10475.jpg',\n",
       " 'image10476.jpg',\n",
       " 'image10477.jpg',\n",
       " 'image10478.jpg',\n",
       " 'image10479.jpg',\n",
       " 'image10480.jpg',\n",
       " 'image10481.jpg',\n",
       " 'image10482.jpg',\n",
       " 'image10483.jpg',\n",
       " 'image10484.jpg',\n",
       " 'image10485.jpg',\n",
       " 'image10486.jpg',\n",
       " 'image10487.jpg',\n",
       " 'image10488.jpg',\n",
       " 'image10489.jpg',\n",
       " 'image10490.jpg',\n",
       " 'image10491.jpg',\n",
       " 'image10492.jpg',\n",
       " 'image10493.jpg',\n",
       " 'image10494.jpg',\n",
       " 'image10495.jpg',\n",
       " 'image10496.jpg',\n",
       " 'image10497.jpg',\n",
       " 'image10498.jpg',\n",
       " 'image10499.jpg',\n",
       " 'image10500.jpg',\n",
       " 'image10501.jpg',\n",
       " 'image10502.jpg',\n",
       " 'image10503.jpg',\n",
       " 'image10504.jpg',\n",
       " 'image10505.jpg',\n",
       " 'image10506.jpg',\n",
       " 'image10507.jpg',\n",
       " 'image10508.jpg',\n",
       " 'image10509.jpg',\n",
       " 'image10510.jpg',\n",
       " 'image10511.jpg',\n",
       " 'image10512.jpg',\n",
       " 'image10513.jpg',\n",
       " 'image10514.jpg',\n",
       " 'image10515.jpg',\n",
       " 'image10516.jpg',\n",
       " 'image10517.jpg',\n",
       " 'image10518.jpg',\n",
       " 'image10519.jpg',\n",
       " 'image10520.jpg',\n",
       " 'image10521.jpg',\n",
       " 'image10522.jpg',\n",
       " 'image10523.jpg',\n",
       " 'image10524.jpg',\n",
       " 'image10525.jpg',\n",
       " 'image10526.jpg',\n",
       " 'image10527.jpg',\n",
       " 'image10528.jpg',\n",
       " 'image10529.jpg',\n",
       " 'image10530.jpg',\n",
       " 'image10531.jpg',\n",
       " 'image10532.jpg',\n",
       " 'image10533.jpg',\n",
       " 'image10534.jpg',\n",
       " 'image10535.jpg',\n",
       " 'image10536.jpg',\n",
       " 'image10537.jpg',\n",
       " 'image10538.jpg',\n",
       " 'image10539.jpg',\n",
       " 'image10540.jpg',\n",
       " 'image10541.jpg',\n",
       " 'image10542.jpg',\n",
       " 'image10543.jpg',\n",
       " 'image10544.jpg',\n",
       " 'image10545.jpg',\n",
       " 'image10546.jpg',\n",
       " 'image10547.jpg',\n",
       " 'image10548.jpg',\n",
       " 'image10549.jpg',\n",
       " 'image10550.jpg',\n",
       " 'image10551.jpg',\n",
       " 'image10552.jpg',\n",
       " 'image10553.jpg',\n",
       " 'image10554.jpg',\n",
       " 'image10555.jpg',\n",
       " 'image10556.jpg',\n",
       " 'image10557.jpg',\n",
       " 'image10558.jpg',\n",
       " 'image10559.jpg',\n",
       " 'image10560.jpg',\n",
       " 'image10561.jpg',\n",
       " 'image10562.jpg',\n",
       " 'image10563.jpg',\n",
       " 'image10564.jpg',\n",
       " 'image10565.jpg',\n",
       " 'image10566.jpg',\n",
       " 'image10567.jpg',\n",
       " 'image10568.jpg',\n",
       " 'image10569.jpg',\n",
       " 'image10570.jpg',\n",
       " 'image10571.jpg',\n",
       " 'image10572.jpg',\n",
       " 'image10573.jpg',\n",
       " 'image10574.jpg',\n",
       " 'image10575.jpg',\n",
       " 'image10576.jpg',\n",
       " 'image10577.jpg',\n",
       " 'image10578.jpg',\n",
       " 'image10579.jpg',\n",
       " 'image10580.jpg',\n",
       " 'image10581.jpg',\n",
       " 'image10582.jpg',\n",
       " 'image10583.jpg',\n",
       " 'image10584.jpg',\n",
       " 'image10585.jpg',\n",
       " 'image10586.jpg',\n",
       " 'image10587.jpg',\n",
       " 'image10588.jpg',\n",
       " 'image10589.jpg',\n",
       " 'image10590.jpg',\n",
       " 'image10591.jpg',\n",
       " 'image10592.jpg',\n",
       " 'image10593.jpg',\n",
       " 'image10594.jpg',\n",
       " 'image10595.jpg',\n",
       " 'image10596.jpg',\n",
       " 'image10597.jpg',\n",
       " 'image10598.jpg',\n",
       " 'image10599.jpg',\n",
       " 'image10600.jpg',\n",
       " 'image10601.jpg',\n",
       " 'image10602.jpg',\n",
       " 'image10603.jpg',\n",
       " 'image10604.jpg',\n",
       " 'image10605.jpg',\n",
       " 'image10606.jpg',\n",
       " 'image10607.jpg',\n",
       " 'image10608.jpg',\n",
       " 'image10609.jpg',\n",
       " 'image10610.jpg',\n",
       " 'image10611.jpg',\n",
       " 'image10612.jpg',\n",
       " 'image10613.jpg',\n",
       " 'image10614.jpg',\n",
       " 'image10615.jpg',\n",
       " 'image10616.jpg',\n",
       " 'image10617.jpg',\n",
       " 'image10618.jpg',\n",
       " 'image10619.jpg',\n",
       " 'image10620.jpg',\n",
       " 'image10621.jpg',\n",
       " 'image10622.jpg',\n",
       " 'image10623.jpg',\n",
       " 'image10624.jpg',\n",
       " 'image10625.jpg',\n",
       " 'image10626.jpg',\n",
       " 'image10627.jpg',\n",
       " 'image10628.jpg',\n",
       " 'image10629.jpg',\n",
       " 'image10630.jpg',\n",
       " 'image10631.jpg',\n",
       " 'image10632.jpg',\n",
       " 'image10633.jpg',\n",
       " 'image10634.jpg',\n",
       " 'image10635.jpg',\n",
       " 'image10636.jpg',\n",
       " 'image10637.jpg',\n",
       " 'image10638.jpg',\n",
       " 'image10639.jpg',\n",
       " 'image10640.jpg',\n",
       " 'image10641.jpg',\n",
       " 'image10642.jpg',\n",
       " 'image10643.jpg',\n",
       " 'image10644.jpg',\n",
       " 'image10645.jpg',\n",
       " 'image10646.jpg',\n",
       " 'image10647.jpg',\n",
       " 'image10648.jpg',\n",
       " 'image10649.jpg',\n",
       " 'image10650.jpg',\n",
       " 'image10651.jpg',\n",
       " 'image10652.jpg',\n",
       " 'image10653.jpg',\n",
       " 'image10654.jpg',\n",
       " 'image10655.jpg',\n",
       " 'image10656.jpg',\n",
       " 'image10657.jpg',\n",
       " 'image10658.jpg',\n",
       " 'image10659.jpg',\n",
       " 'image10660.jpg',\n",
       " 'image10661.jpg',\n",
       " 'image10662.jpg',\n",
       " 'image10663.jpg',\n",
       " 'image10664.jpg',\n",
       " 'image10665.jpg',\n",
       " 'image10666.jpg',\n",
       " 'image10667.jpg',\n",
       " 'image10668.jpg',\n",
       " 'image10669.jpg',\n",
       " 'image10670.jpg',\n",
       " 'image10671.jpg',\n",
       " 'image10672.jpg',\n",
       " 'image10673.jpg',\n",
       " 'image10674.jpg',\n",
       " 'image10675.jpg',\n",
       " 'image10676.jpg',\n",
       " 'image10677.jpg',\n",
       " 'image10678.jpg',\n",
       " 'image10679.jpg',\n",
       " 'image10680.jpg',\n",
       " 'image10681.jpg',\n",
       " 'image10682.jpg',\n",
       " 'image10683.jpg',\n",
       " 'image10684.jpg',\n",
       " 'image10685.jpg',\n",
       " 'image10686.jpg',\n",
       " 'image10687.jpg',\n",
       " 'image10688.jpg',\n",
       " 'image10689.jpg',\n",
       " 'image10690.jpg',\n",
       " 'image10691.jpg',\n",
       " 'image10692.jpg',\n",
       " 'image10693.jpg',\n",
       " 'image10694.jpg',\n",
       " 'image10695.jpg',\n",
       " 'image10696.jpg',\n",
       " 'image10697.jpg',\n",
       " 'image10698.jpg',\n",
       " 'image10699.jpg',\n",
       " 'image10700.jpg',\n",
       " 'image10701.jpg',\n",
       " 'image10702.jpg',\n",
       " 'image10703.jpg',\n",
       " 'image10704.jpg',\n",
       " 'image10705.jpg',\n",
       " 'image10706.jpg',\n",
       " 'image10707.jpg',\n",
       " 'image10708.jpg',\n",
       " 'image10709.jpg',\n",
       " 'image10710.jpg',\n",
       " 'image10711.jpg',\n",
       " 'image10712.jpg',\n",
       " 'image10713.jpg',\n",
       " 'image10714.jpg',\n",
       " 'image10715.jpg',\n",
       " 'image10716.jpg',\n",
       " 'image10717.jpg',\n",
       " 'image10718.jpg',\n",
       " 'image10719.jpg',\n",
       " 'image10720.jpg',\n",
       " 'image10721.jpg',\n",
       " 'image10722.jpg',\n",
       " 'image10723.jpg',\n",
       " 'image10724.jpg',\n",
       " 'image10725.jpg',\n",
       " 'image10726.jpg',\n",
       " 'image10727.jpg',\n",
       " 'image10728.jpg',\n",
       " 'image10729.jpg',\n",
       " 'image10730.jpg',\n",
       " 'image10731.jpg',\n",
       " 'image10732.jpg',\n",
       " 'image10733.jpg',\n",
       " 'image10734.jpg',\n",
       " 'image10735.jpg',\n",
       " 'image10736.jpg',\n",
       " 'image10737.jpg',\n",
       " 'image10738.jpg',\n",
       " 'image10739.jpg',\n",
       " 'image10740.jpg',\n",
       " 'image10741.jpg',\n",
       " 'image10742.jpg',\n",
       " 'image10743.jpg',\n",
       " 'image10744.jpg',\n",
       " 'image10745.jpg',\n",
       " 'image10746.jpg',\n",
       " 'image10747.jpg',\n",
       " 'image10748.jpg',\n",
       " 'image10749.jpg',\n",
       " 'image10750.jpg',\n",
       " 'image10751.jpg',\n",
       " 'image10752.jpg',\n",
       " 'image10753.jpg',\n",
       " 'image10754.jpg',\n",
       " 'image10755.jpg',\n",
       " 'image10756.jpg',\n",
       " 'image10757.jpg',\n",
       " 'image10758.jpg',\n",
       " 'image10759.jpg',\n",
       " 'image10760.jpg',\n",
       " 'image10761.jpg',\n",
       " 'image10762.jpg',\n",
       " 'image10763.jpg',\n",
       " 'image10764.jpg',\n",
       " 'image10765.jpg',\n",
       " 'image10766.jpg',\n",
       " 'image10767.jpg',\n",
       " 'image10768.jpg',\n",
       " 'image10769.jpg',\n",
       " 'image10770.jpg',\n",
       " 'image10771.jpg',\n",
       " 'image10772.jpg',\n",
       " 'image10773.jpg',\n",
       " 'image10774.jpg',\n",
       " 'image10775.jpg',\n",
       " 'image10776.jpg',\n",
       " 'image10777.jpg',\n",
       " 'image10778.jpg',\n",
       " 'image10779.jpg',\n",
       " 'image10780.jpg',\n",
       " 'image10781.jpg',\n",
       " 'image10782.jpg',\n",
       " 'image10783.jpg',\n",
       " 'image10784.jpg',\n",
       " 'image10785.jpg',\n",
       " 'image10786.jpg',\n",
       " 'image10787.jpg',\n",
       " 'image10788.jpg',\n",
       " 'image10789.jpg',\n",
       " 'image10790.jpg',\n",
       " 'image10791.jpg',\n",
       " 'image10792.jpg',\n",
       " 'image10793.jpg',\n",
       " 'image10794.jpg',\n",
       " 'image10795.jpg',\n",
       " 'image10796.jpg',\n",
       " 'image10797.jpg',\n",
       " 'image10798.jpg',\n",
       " 'image10799.jpg',\n",
       " 'image10800.jpg',\n",
       " 'image10801.jpg',\n",
       " 'image10802.jpg',\n",
       " 'image10803.jpg',\n",
       " 'image10804.jpg',\n",
       " 'image10805.jpg',\n",
       " 'image10806.jpg',\n",
       " 'image10807.jpg',\n",
       " 'image10808.jpg',\n",
       " 'image10809.jpg',\n",
       " 'image10810.jpg',\n",
       " 'image10811.jpg',\n",
       " 'image10812.jpg',\n",
       " 'image10813.jpg',\n",
       " 'image10814.jpg',\n",
       " 'image10815.jpg',\n",
       " 'image10816.jpg',\n",
       " 'image10817.jpg',\n",
       " 'image10818.jpg',\n",
       " 'image10819.jpg',\n",
       " 'image10820.jpg',\n",
       " 'image10821.jpg',\n",
       " 'image10822.jpg',\n",
       " 'image10823.jpg',\n",
       " 'image10824.jpg',\n",
       " 'image10825.jpg',\n",
       " 'image10826.jpg',\n",
       " 'image10827.jpg',\n",
       " 'image10828.jpg',\n",
       " 'image10829.jpg',\n",
       " 'image10830.jpg',\n",
       " 'image10831.jpg',\n",
       " 'image10832.jpg',\n",
       " 'image10833.jpg',\n",
       " 'image10834.jpg',\n",
       " 'image10835.jpg',\n",
       " 'image10836.jpg',\n",
       " 'image10837.jpg',\n",
       " 'image10838.jpg',\n",
       " 'image10839.jpg',\n",
       " 'image10840.jpg',\n",
       " 'image10841.jpg',\n",
       " 'image10842.jpg',\n",
       " 'image10843.jpg',\n",
       " 'image10844.jpg',\n",
       " 'image10845.jpg',\n",
       " 'image10846.jpg',\n",
       " 'image10847.jpg',\n",
       " 'image10848.jpg',\n",
       " 'image10849.jpg',\n",
       " 'image10850.jpg',\n",
       " 'image10851.jpg',\n",
       " 'image10852.jpg',\n",
       " 'image10853.jpg',\n",
       " 'image10854.jpg',\n",
       " 'image10855.jpg',\n",
       " 'image10856.jpg',\n",
       " 'image10857.jpg',\n",
       " 'image10858.jpg',\n",
       " 'image10859.jpg',\n",
       " 'image10860.jpg',\n",
       " 'image10861.jpg',\n",
       " 'image10862.jpg',\n",
       " 'image10863.jpg',\n",
       " 'image10864.jpg',\n",
       " 'image10865.jpg',\n",
       " 'image10866.jpg',\n",
       " 'image10867.jpg',\n",
       " 'image10868.jpg',\n",
       " 'image10869.jpg',\n",
       " 'image10870.jpg',\n",
       " 'image10871.jpg',\n",
       " 'image10872.jpg',\n",
       " 'image10873.jpg',\n",
       " 'image10874.jpg',\n",
       " 'image10875.jpg',\n",
       " 'image10876.jpg',\n",
       " 'image10877.jpg',\n",
       " 'image10878.jpg',\n",
       " 'image10879.jpg',\n",
       " 'image10880.jpg',\n",
       " 'image10881.jpg',\n",
       " 'image10882.jpg',\n",
       " 'image10883.jpg',\n",
       " 'image10884.jpg',\n",
       " 'image10885.jpg',\n",
       " 'image10886.jpg',\n",
       " 'image10887.jpg',\n",
       " 'image10888.jpg',\n",
       " 'image10889.jpg',\n",
       " 'image10890.jpg',\n",
       " 'image10891.jpg',\n",
       " 'image10892.jpg',\n",
       " 'image10893.jpg',\n",
       " 'image10894.jpg',\n",
       " 'image10895.jpg',\n",
       " 'image10896.jpg',\n",
       " 'image10897.jpg',\n",
       " 'image10898.jpg',\n",
       " 'image10899.jpg',\n",
       " 'image10900.jpg',\n",
       " 'image10901.jpg',\n",
       " 'image10902.jpg',\n",
       " 'image10903.jpg',\n",
       " 'image10904.jpg',\n",
       " 'image10905.jpg',\n",
       " 'image10906.jpg',\n",
       " 'image10907.jpg',\n",
       " 'image10908.jpg',\n",
       " 'image10909.jpg',\n",
       " 'image10910.jpg',\n",
       " 'image10911.jpg',\n",
       " 'image10912.jpg',\n",
       " 'image10913.jpg',\n",
       " 'image10914.jpg',\n",
       " 'image10915.jpg',\n",
       " 'image10916.jpg',\n",
       " 'image10917.jpg',\n",
       " 'image10918.jpg',\n",
       " 'image10919.jpg',\n",
       " 'image10920.jpg',\n",
       " 'image10921.jpg',\n",
       " 'image10922.jpg',\n",
       " 'image10923.jpg',\n",
       " 'image10924.jpg',\n",
       " 'image10925.jpg',\n",
       " 'image10926.jpg',\n",
       " 'image10927.jpg',\n",
       " 'image10928.jpg',\n",
       " 'image10929.jpg',\n",
       " 'image10930.jpg',\n",
       " 'image10931.jpg',\n",
       " 'image10932.jpg',\n",
       " 'image10933.jpg',\n",
       " 'image10934.jpg',\n",
       " 'image10935.jpg',\n",
       " 'image10936.jpg',\n",
       " 'image10937.jpg',\n",
       " 'image10938.jpg',\n",
       " 'image10939.jpg',\n",
       " 'image10940.jpg',\n",
       " 'image10941.jpg',\n",
       " 'image10942.jpg',\n",
       " 'image10943.jpg',\n",
       " 'image10944.jpg',\n",
       " 'image10945.jpg',\n",
       " 'image10946.jpg',\n",
       " 'image10947.jpg',\n",
       " 'image10948.jpg',\n",
       " 'image10949.jpg',\n",
       " 'image10950.jpg',\n",
       " 'image10951.jpg',\n",
       " 'image10952.jpg',\n",
       " 'image10953.jpg',\n",
       " 'image10954.jpg',\n",
       " 'image10955.jpg',\n",
       " 'image10956.jpg',\n",
       " 'image10957.jpg',\n",
       " 'image10958.jpg',\n",
       " 'image10959.jpg',\n",
       " 'image10960.jpg',\n",
       " 'image10961.jpg',\n",
       " 'image10962.jpg',\n",
       " 'image10963.jpg',\n",
       " 'image10964.jpg',\n",
       " 'image10965.jpg',\n",
       " 'image10966.jpg',\n",
       " 'image10967.jpg',\n",
       " 'image10968.jpg',\n",
       " 'image10969.jpg',\n",
       " 'image10970.jpg',\n",
       " 'image10971.jpg',\n",
       " 'image10972.jpg',\n",
       " 'image10973.jpg',\n",
       " 'image10974.jpg',\n",
       " 'image10975.jpg',\n",
       " 'image10976.jpg',\n",
       " 'image10977.jpg',\n",
       " 'image10978.jpg',\n",
       " 'image10979.jpg',\n",
       " 'image10980.jpg',\n",
       " 'image10981.jpg',\n",
       " 'image10982.jpg',\n",
       " 'image10983.jpg',\n",
       " 'image10984.jpg',\n",
       " 'image10985.jpg',\n",
       " 'image10986.jpg',\n",
       " 'image10987.jpg',\n",
       " 'image10988.jpg',\n",
       " 'image10989.jpg',\n",
       " 'image10990.jpg',\n",
       " 'image10991.jpg',\n",
       " 'image10992.jpg',\n",
       " 'image10993.jpg',\n",
       " 'image10994.jpg',\n",
       " 'image10995.jpg',\n",
       " 'image10996.jpg',\n",
       " 'image10997.jpg',\n",
       " 'image10998.jpg',\n",
       " 'image10999.jpg',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d8d0fa7-1582-4e45-b540-b0c5a915f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with image paths and predicted labels\n",
    "df = pd.DataFrame({'Image_Path': img_path, 'Predicted_Labels': test_predicted_labels})\n",
    "\n",
    "# Specify the path where you want to save the Excel file\n",
    "excel_file_path = r'D:\\PCOS_Challenge\\pred_labels_of_test_images.xlsx'\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel(excel_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adce731a-2368-4656-bbf6-c9811c594d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
